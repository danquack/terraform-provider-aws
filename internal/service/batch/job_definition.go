// Code generated by tools/tfsdk2fw/main.go. Manual editing is required.

package batch

import (
	"context"
	"encoding/json"
	"fmt"
	"regexp"
	"strings"

	"github.com/aws/aws-sdk-go/aws"
	"github.com/aws/aws-sdk-go/service/batch"
	"github.com/hashicorp/terraform-plugin-framework-validators/int64validator"
	"github.com/hashicorp/terraform-plugin-framework-validators/resourcevalidator"
	"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator"
	"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry"

	"github.com/hashicorp/terraform-plugin-framework/diag"
	"github.com/hashicorp/terraform-plugin-framework/path"
	"github.com/hashicorp/terraform-plugin-framework/resource"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier"
	"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier"
	"github.com/hashicorp/terraform-plugin-framework/schema/validator"
	"github.com/hashicorp/terraform-plugin-framework/types"
	"github.com/hashicorp/terraform-plugin-log/tflog"
	"github.com/hashicorp/terraform-provider-aws/internal/errs/fwdiag"
	"github.com/hashicorp/terraform-provider-aws/internal/framework"
	"github.com/hashicorp/terraform-provider-aws/internal/framework/flex"
	fwTypes "github.com/hashicorp/terraform-provider-aws/internal/framework/types"
	tftags "github.com/hashicorp/terraform-provider-aws/internal/tags"
	"github.com/hashicorp/terraform-provider-aws/internal/tfresource"
)

const (
	jobDefinitionStatusInactive = "INACTIVE"
	jobDefinitionStatusActive   = "ACTIVE"
)

// @FrameworkResource(name = "Resource Job Definition")
// @Tags(identifierAttribute="arn")
func newResourceJobDefinition(context.Context) (resource.ResourceWithConfigure, error) {
	r := &resourceJobDefinition{}
	r.SetMigratedFromPluginSDK(true)

	return r, nil
}

type resourceJobDefinition struct {
	framework.ResourceWithConfigure
	framework.WithImportByID
	framework.WithTimeouts
}

func (r *resourceJobDefinition) Create(ctx context.Context, request resource.CreateRequest, response *resource.CreateResponse) {
	var data resourceJobDefinitionData

	response.Diagnostics.Append(request.Plan.Get(ctx, &data)...)

	if response.Diagnostics.HasError() {
		return
	}

	conn := r.Meta().BatchConn(ctx)

	// Type differences require us to nullify these for now.
	input := &batch.RegisterJobDefinitionInput{}
	response.Diagnostics.Append(flex.Expand(ctx, input, &data)...)
	if response.Diagnostics.HasError() {
		return
	}
	jobDefinitionType := data.Type.ValueString()
	if jobDefinitionType == batch.JobDefinitionTypeContainer {
		if !data.NodeProperties.IsNull() {
			response.Diagnostics.Append(
				diag.NewAttributeErrorDiagnostic(path.Root("node_properties"), fmt.Sprintf("No `node_properties` can be specified when `type` is %q", jobDefinitionType), ""),
			)
			return
		}
		if !data.ContainerProperties.IsNull() {
			props, err := expandJobContainerProperties(data.ContainerProperties.ValueString())
			if err != nil {
				response.Diagnostics.Append(
					diag.NewAttributeErrorDiagnostic(path.Root("container_properties"), fmt.Sprintf("creating Batch Job Definition (%s)", data.Name.ValueString()), err.Error()),
				)
				return
			}

			if aws.StringValue(input.Type) == batch.JobDefinitionTypeContainer {
				removeEmptyEnvironmentVariables(response.Diagnostics, props.Environment, path.Root("container_properties"))
				input.ContainerProperties = props
			}
		}
	}

	if jobDefinitionType == batch.JobDefinitionTypeMultinode {
		if !data.ContainerProperties.IsNull() {
			response.Diagnostics.Append(
				diag.NewAttributeErrorDiagnostic(path.Root("container_properties"), fmt.Sprintf("No `container_properties` can be specified when `type` is %q", jobDefinitionType), ""),
			)
			return
		}

		if !data.NodeProperties.IsNull() {
			props, err := expandJobNodeProperties(data.NodeProperties.ValueString())
			if err != nil {
				response.Diagnostics.Append(
					diag.NewAttributeErrorDiagnostic(path.Root("node_properties"), fmt.Sprintf("creating Batch Job Definition (%s)", data.Name.ValueString()), err.Error()),
				)
				return
			}

			for _, node := range props.NodeRangeProperties {
				removeEmptyEnvironmentVariables(response.Diagnostics, node.Container.Environment, path.Root("node_properties"))
			}
			input.NodeProperties = props
		}
	}

	output, err := conn.RegisterJobDefinitionWithContext(ctx, input)
	if err != nil {
		response.Diagnostics.Append(
			diag.NewErrorDiagnostic(
				fmt.Sprintf("creating Batch Job Definition (%s)", data.Name.ValueString()),
				err.Error(),
			),
		)
		return
	}

	// Set values for unknowns.
	response.Diagnostics.Append(flex.Flatten(ctx, output, &data)...)

	if response.Diagnostics.HasError() {
		return
	}

	data.ArnPrefix = types.StringValue(
		strings.TrimSuffix(*output.JobDefinitionArn, fmt.Sprintf(":%d", *output.Revision)),
	)

	response.Diagnostics.Append(response.State.Set(ctx, &data)...)
}

func (r *resourceJobDefinition) Metadata(_ context.Context, request resource.MetadataRequest, response *resource.MetadataResponse) {
	response.TypeName = "aws_batch_job_definition"
}

// Schema returns the schema for this resource.
func (r *resourceJobDefinition) Schema(ctx context.Context, request resource.SchemaRequest, response *resource.SchemaResponse) {
	s := schema.Schema{
		Attributes: map[string]schema.Attribute{
			"arn": framework.ARNAttributeComputedOnly(),
			"arn_prefix": schema.StringAttribute{
				Computed: true,
			},
			"container_properties": schema.StringAttribute{
				Optional: true,
				// TODO Validate,
			},
			"deregister_on_new_revision": schema.BoolAttribute{
				Optional: true,
				Computed: true,
				Default:  booldefault.StaticBool(true),
			},
			"id": framework.IDAttribute(),
			"name": schema.StringAttribute{
				Required: true,
				PlanModifiers: []planmodifier.String{
					stringplanmodifier.RequiresReplace(),
				},
				Validators: []validator.String{
					stringvalidator.RegexMatches(regexp.MustCompile("^[0-9A-Za-z]{1}[0-9A-Za-z_-]{0,127}$"), " must be up to 128 letters (uppercase and lowercase), numbers, underscores and dashes, and must start with an alphanumeric."),
				},
			},
			"node_properties": schema.StringAttribute{
				Optional: true,
				// TODO Validate,
			},
			// "parameters": schema.MapAttribute{
			// 	ElementType: types.StringType,
			// 	Optional:    true,
			// },
			// "platform_capabilities": schema.SetAttribute{
			// 	ElementType: types.StringType,
			// 	Optional:    true,
			// 	Validators: []validator.Set{
			// 		setvalidator.ValueStringsAre(
			// 			stringvalidator.OneOfCaseInsensitive(batch.PlatformCapability_Values()...),
			// 		),
			// 	},
			// },
			"propagate_tags": schema.BoolAttribute{
				Optional: true,
				Computed: true,
				Default:  booldefault.StaticBool(false),
			},
			"revision": schema.Int64Attribute{
				Computed: true,
			},
			// "scheduling_priority": schema.Int64Attribute{
			// 	Optional: true,
			// },
			"tags":     tftags.TagsAttribute(),
			"tags_all": tftags.TagsAttributeComputedOnly(),
			"type": schema.StringAttribute{
				Required: true,
				Validators: []validator.String{
					stringvalidator.OneOfCaseInsensitive(batch.JobDefinitionType_Values()...),
				},
			},
		},
		Blocks: map[string]schema.Block{
			"retry_strategy": schema.ListNestedBlock{
				CustomType: fwTypes.NewListNestedObjectTypeOf[retryStrategy](ctx),
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"attempts": schema.Int64Attribute{
							Optional: true,
							Validators: []validator.Int64{
								int64validator.Between(1, 10),
							},
						},
					},
					Blocks: map[string]schema.Block{
						"evaluate_on_exit": schema.ListNestedBlock{
							CustomType: fwTypes.NewListNestedObjectTypeOf[evaluateOnExit](ctx),
							NestedObject: schema.NestedBlockObject{
								Attributes: map[string]schema.Attribute{
									"action": schema.StringAttribute{
										Required: true,
										Validators: []validator.String{
											stringvalidator.OneOfCaseInsensitive(batch.RetryAction_Values()...),
										},
									},
									"on_exit_code": schema.StringAttribute{
										Optional: true,
										Validators: []validator.String{
											stringvalidator.LengthBetween(1, 512),
											stringvalidator.RegexMatches(regexp.MustCompile(`^[0-9]*\*?$`), "must contain only numbers, and can optionally end with an asterisk"),
										},
									},
									"on_reason": schema.StringAttribute{
										Optional: true,
										Validators: []validator.String{
											stringvalidator.LengthBetween(1, 512),
											stringvalidator.RegexMatches(regexp.MustCompile(`^[0-9A-Za-z.:\s]*\*?$`), "must contain letters, numbers, periods, colons, and white space, and can optionally end with an asterisk"),
										},
									},
									"on_status_reason": schema.StringAttribute{
										Optional: true,
										Validators: []validator.String{
											stringvalidator.LengthBetween(1, 512),
											stringvalidator.RegexMatches(regexp.MustCompile(`^[0-9A-Za-z.:\s]*\*?$`), "must contain letters, numbers, periods, colons, and white space, and can optionally end with an asterisk"),
										},
									},
								},
							},
						},
					},
				},
			},
			"timeout": schema.ListNestedBlock{
				CustomType: fwTypes.NewListNestedObjectTypeOf[timeout](ctx),
				NestedObject: schema.NestedBlockObject{
					Attributes: map[string]schema.Attribute{
						"attempt_duration_seconds": schema.Int64Attribute{
							Optional: true,
							Computed: true,
						},
					},
				},
			},
		},
	}
	response.Schema = s
}

// Planned state values should be read from the ReadRequest and new state values set on the ReadResponse.
func (r *resourceJobDefinition) Read(ctx context.Context, request resource.ReadRequest, response *resource.ReadResponse) {
	var data resourceJobDefinitionData

	response.Diagnostics.Append(request.State.Get(ctx, &data)...)

	if response.Diagnostics.HasError() {
		return
	}

	conn := r.Meta().BatchConn(ctx)
	jobDefinition, err := FindJobDefinitionByARN(ctx, conn, data.ID.ValueString())
	if err != nil {
		response.Diagnostics.Append(fwdiag.NewResourceNotFoundWarningDiagnostic(err))
		return
	}

	response.Diagnostics.Append(flex.Flatten(ctx, &data, jobDefinition)...)
	data.ArnPrefix = types.StringValue(
		strings.TrimSuffix(*jobDefinition.JobDefinitionArn, fmt.Sprintf(":%d", *jobDefinition.Revision)),
	)
	response.Diagnostics.Append(response.State.Set(ctx, &data)...)
}

// Update is called to update the state of the resource.
// Config, planned state, and prior state values should be read from the UpdateRequest and new state values set on the UpdateResponse.
func (r *resourceJobDefinition) Update(ctx context.Context, request resource.UpdateRequest, response *resource.UpdateResponse) {
	var old, new resourceJobDefinitionData

	response.Diagnostics.Append(request.State.Get(ctx, &old)...)

	if response.Diagnostics.HasError() {
		return
	}

	response.Diagnostics.Append(request.Plan.Get(ctx, &new)...)

	if response.Diagnostics.HasError() {
		return
	}

	response.Diagnostics.Append(response.State.Set(ctx, &new)...)
}

func (r *resourceJobDefinition) Delete(ctx context.Context, request resource.DeleteRequest, response *resource.DeleteResponse) {
	var data resourceJobDefinitionData

	response.Diagnostics.Append(request.State.Get(ctx, &data)...)
	conn := r.Meta().BatchConn(ctx)

	if response.Diagnostics.HasError() {
		return
	}

	jds, err := ListActiveJobDefinitionByName(ctx, conn, data.Name.ValueString())
	if err != nil {
		response.Diagnostics.Append(
			diag.NewErrorDiagnostic(
				fmt.Sprintf("deleting Batch Job Definitions (%s)", data.Name.ValueString()),
				err.Error(),
			),
		)
		return
	}

	for i := range jds {
		arn := aws.StringValue(jds[i].JobDefinitionArn)
		tflog.Debug(ctx, "[DEBUG] Deleting Batch Job Definition: %s", map[string]interface{}{
			"arn": arn,
		})
		_, err := conn.DeregisterJobDefinitionWithContext(ctx, &batch.DeregisterJobDefinitionInput{
			JobDefinition: aws.String(arn),
		})

		if err != nil {
			response.Diagnostics.Append(
				diag.NewErrorDiagnostic(
					fmt.Sprintf("deleting Batch Job Definitions (%s)", data.Name.ValueString()),
					err.Error(),
				),
			)
			return
		}
	}
}

// ImportState is called when the provider must import the state of a resource instance.
// This method must return enough state so the Read method can properly refresh the full resource.
//
// If setting an attribute with the import identifier, it is recommended to use the ImportStatePassthroughID() call in this method.
func (r *resourceJobDefinition) ImportState(ctx context.Context, request resource.ImportStateRequest, response *resource.ImportStateResponse) {
	resource.ImportStatePassthroughID(ctx, path.Root("id"), request, response)
}

// ModifyPlan is called when the provider has an opportunity to modify
// the plan: once during the plan phase when Terraform is determining
// the diff that should be shown to the user for approval, and once
// during the apply phase with any unknown values from configuration
// filled in with their final values.
//
// The planned new state is represented by
// ModifyPlanResponse.Plan. It must meet the following
// constraints:
// 1. Any non-Computed attribute set in config must preserve the exact
// config value or return the corresponding attribute value from the
// prior state (ModifyPlanRequest.State).
// 2. Any attribute with a known value must not have its value changed
// in subsequent calls to ModifyPlan or Create/Read/Update.
// 3. Any attribute with an unknown value may either remain unknown
// or take on any value of the expected type.
//
// Any errors will prevent further resource-level plan modifications.
func (r *resourceJobDefinition) ModifyPlan(ctx context.Context, request resource.ModifyPlanRequest, response *resource.ModifyPlanResponse) {
	r.SetTagsAll(ctx, request, response)
}

func (r resourceJobDefinition) ConfigValidators(ctx context.Context) []resource.ConfigValidator {
	return []resource.ConfigValidator{
		resourcevalidator.Conflicting(
			path.MatchRoot("container_properties"),
			path.MatchRoot("node_properties"),
		),
	}
}

func FindJobDefinitionByARN(ctx context.Context, conn *batch.Batch, arn string) (*batch.JobDefinition, error) {
	input := &batch.DescribeJobDefinitionsInput{
		JobDefinitions: aws.StringSlice([]string{arn}),
	}

	output, err := findJobDefinition(ctx, conn, input)

	if err != nil {
		return nil, err
	}

	if status := aws.StringValue(output.Status); status == jobDefinitionStatusInactive {
		return nil, &retry.NotFoundError{
			Message:     status,
			LastRequest: input,
		}
	}

	return output, nil
}

func findJobDefinition(ctx context.Context, conn *batch.Batch, input *batch.DescribeJobDefinitionsInput) (*batch.JobDefinition, error) {
	output, err := conn.DescribeJobDefinitionsWithContext(ctx, input)

	if err != nil {
		return nil, err
	}

	if output == nil || len(output.JobDefinitions) == 0 || output.JobDefinitions[0] == nil {
		return nil, tfresource.NewEmptyResultError(input)
	}

	if count := len(output.JobDefinitions); count > 1 {
		return nil, tfresource.NewTooManyResultsError(count, input)
	}

	return output.JobDefinitions[0], nil
}

func ListActiveJobDefinitionByName(ctx context.Context, conn *batch.Batch, name string) ([]*batch.JobDefinition, error) {
	input := &batch.DescribeJobDefinitionsInput{
		JobDefinitionName: aws.String(name),
		Status:            aws.String(jobDefinitionStatusActive),
	}

	output, err := conn.DescribeJobDefinitionsWithContext(ctx, input)

	if err != nil {
		return nil, err
	}

	return output.JobDefinitions, nil
}

func validJobContainerProperties(v interface{}, k string) (ws []string, errors []error) {
	value := v.(string)
	_, err := expandJobContainerProperties(value)
	if err != nil {
		errors = append(errors, fmt.Errorf("AWS Batch Job container_properties is invalid: %s", err))
	}
	return
}

func expandJobContainerProperties(rawProps string) (*batch.ContainerProperties, error) {
	var props *batch.ContainerProperties

	err := json.Unmarshal([]byte(rawProps), &props)
	if err != nil {
		return nil, fmt.Errorf("decoding JSON: %s", err)
	}

	return props, nil
}

func validJobNodeProperties(v interface{}, k string) (ws []string, errors []error) {
	value := v.(string)
	_, err := expandJobNodeProperties(value)
	if err != nil {
		errors = append(errors, fmt.Errorf("AWS Batch Job node_properties is invalid: %s", err))
	}
	return
}

func expandJobNodeProperties(rawProps string) (*batch.NodeProperties, error) {
	var props *batch.NodeProperties

	err := json.Unmarshal([]byte(rawProps), &props)
	if err != nil {
		return nil, fmt.Errorf("decoding JSON: %s", err)
	}

	return props, nil
}

func removeEmptyEnvironmentVariables(diags diag.Diagnostics, environment []*batch.KeyValuePair, attributePath path.Path) {
	for _, env := range environment {
		if aws.StringValue(env.Value) == "" {
			diags.Append(
				diag.NewAttributeErrorDiagnostic(
					attributePath,
					"Ignoring environment variable",
					fmt.Sprintf("The environment variable %q has an empty value, which is ignored by the Batch service", aws.StringValue(env.Name)),
				),
			)
		}
	}
}

type JobDefinitionInputModified struct {
	batch.RegisterJobDefinitionInput
	NodeProperties      types.String
	ContainerProperties types.String
}

type resourceJobDefinitionData struct {
	ARN                     types.String `tfsdk:"arn"`
	ArnPrefix               types.String `tfsdk:"arn_prefix"`
	ContainerProperties     types.String `tfsdk:"container_properties"`
	DeregisterOnNewRevision types.Bool   `tfsdk:"deregister_on_new_revision"`
	ID                      types.String `tfsdk:"id"`
	Name                    types.String `tfsdk:"name"`
	NodeProperties          types.String `tfsdk:"node_properties"`
	// Parameters              types.Map                                      `tfsdk:"parameters"`
	// PlatformCapabilities types.Set                                      `tfsdk:"platform_capabilities"`
	PropagateTags types.Bool  `tfsdk:"propagate_tags"`
	Revision      types.Int64 `tfsdk:"revision"`
	// SchedulingPriority types.Int64                                    `tfsdk:"scheduling_priority"`
	Tags          types.Map                                      `tfsdk:"tags"`
	TagsAll       types.Map                                      `tfsdk:"tags_all"`
	Type          types.String                                   `tfsdk:"type"`
	RetryStrategy fwTypes.ListNestedObjectValueOf[retryStrategy] `tfsdk:"retry_strategy"`
	Timeout       fwTypes.ListNestedObjectValueOf[timeout]       `tfsdk:"timeout"`
}

type retryStrategy struct {
	Attempts       types.Int64                                     `tfsdk:"attempts"`
	EvaluateOnExit fwTypes.ListNestedObjectValueOf[evaluateOnExit] `tfsdk:"evaluate_on_exit"`
}

type evaluateOnExit struct {
	Action         types.String `tfsdk:"action"`
	OnExitCode     types.String `tfsdk:"on_exit_code"`
	OnReason       types.String `tfsdk:"on_reason"`
	OnStatusReason types.String `tfsdk:"on_status_reason"`
}

type timeout struct {
	AttemptDurationSeconds types.Int64 `tfsdk:"attempt_duration_seconds"`
}
